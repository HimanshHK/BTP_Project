{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn-extra in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (0.3.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn-extra) (1.23.5)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn-extra) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=0.23.0 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn-extra) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn>=0.23.0->scikit-learn-extra) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn>=0.23.0->scikit-learn-extra) (3.2.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.3.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.22.3)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\python311\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.54.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.28.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\himanshu\\appdata\\roaming\\python\\python311\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install scikit-learn-extra\n",
    "! pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Reading and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the malware dataset\n",
    "data = pd.read_csv('Malware_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "millisecond          0\n",
      "classification       0\n",
      "state                0\n",
      "usage_counter        0\n",
      "prio                 0\n",
      "static_prio          0\n",
      "normal_prio          0\n",
      "policy               0\n",
      "vm_pgoff             0\n",
      "vm_truncate_count    0\n",
      "task_size            0\n",
      "cached_hole_size     0\n",
      "free_area_cache      0\n",
      "mm_users             0\n",
      "map_count            0\n",
      "hiwater_rss          0\n",
      "total_vm             0\n",
      "shared_vm            0\n",
      "exec_vm              0\n",
      "reserved_vm          0\n",
      "nr_ptes              0\n",
      "end_data             0\n",
      "last_interval        0\n",
      "nvcsw                0\n",
      "nivcsw               0\n",
      "min_flt              0\n",
      "maj_flt              0\n",
      "fs_excl_counter      0\n",
      "lock                 0\n",
      "utime                0\n",
      "stime                0\n",
      "gtime                0\n",
      "cgtime               0\n",
      "signal_nvcsw         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define the number of clients\n",
    "num_clients = 3\n",
    "\n",
    "#removing unwanted columns\n",
    "data.drop('hash', axis=1, inplace=True)\n",
    "# check for missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Randomly select 100 rows from the dataset\n",
    "data = data.sample(n=10000, random_state=42)\n",
    "\n",
    "\n",
    "# get the number of unique values in each column\n",
    "unique_counts = data.nunique()\n",
    "\n",
    "\n",
    "# get the list of columns to drop\n",
    "to_drop = [col for col in unique_counts.index if unique_counts[col] == len(data)]\n",
    "\n",
    "# drop the columns\n",
    "data.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "X = data.drop('classification', axis=1)\n",
    "y = data['classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition the dataset among the clients\n",
    "X_partitions = []\n",
    "y_partitions = []\n",
    "\n",
    "for i in range(num_clients):\n",
    "    # Split the dataset randomly\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=i)\n",
    "    \n",
    "    # Append the training set to the partitions\n",
    "    X_partitions.append(X_train)\n",
    "    y_partitions.append(y_train)\n",
    "    \n",
    "# Convert the partitions to numpy arrays\n",
    "X_partitions = [pd.DataFrame(X) for X in X_partitions]\n",
    "y_partitions = [pd.DataFrame(y) for y in y_partitions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated data for demonstration purposes\n",
    "num_clients = 10\n",
    "client_data_size = 1000\n",
    "num_features = 33\n",
    "\n",
    "# Generate simulated data\n",
    "def generate_simulated_data(num_clients, client_data_size, num_features):\n",
    "    client_data = []\n",
    "    client_labels = []\n",
    "\n",
    "    for _ in range(num_clients):\n",
    "        x_data = np.random.rand(client_data_size, num_features)\n",
    "        y_labels = np.random.choice([0, 1], size=client_data_size)\n",
    "        client_data.append((x_data, y_labels))\n",
    "        client_labels.append(y_labels)\n",
    "\n",
    "    return client_data, client_labels\n",
    "\n",
    "client_data, client_labels = generate_simulated_data(num_clients, client_data_size, num_features)\n",
    "\n",
    "# Define the global model (neural network) to accept features and labels as inputs\n",
    "global_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(num_features,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Define a custom loss function that takes both features and labels as inputs\n",
    "def custom_loss(y_true, y_pred):\n",
    "    return tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "# Federated learning parameters\n",
    "num_rounds = 10\n",
    "epochs_per_client = 5\n",
    "\n",
    "\n",
    "class CustomModel(tf.keras.Model):\n",
    "    def __init__(self, num_features):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(64, activation='relu', input_shape=(num_features,))\n",
    "        self.dense2 = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features, labels = inputs\n",
    "        features = tf.cast(features, dtype=tf.float32)  # Ensure features are of float32 dtype\n",
    "        \n",
    "        # Cast labels to float32 to match the data type of features\n",
    "        labels = tf.cast(labels, dtype=tf.float32)\n",
    "\n",
    "        # Concatenate labels as an additional feature\n",
    "        x = tf.concat([features, labels[:, tf.newaxis]], axis=-1)\n",
    "        \n",
    "        logits = self.dense2(x)\n",
    "        return logits\n",
    "\n",
    "# Define a custom dataset to handle features and labels\n",
    "def create_dataset(features, labels, batch_size=32):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "# Create a dataset for test data\n",
    "test_data, test_labels = generate_simulated_data(1, 1000, num_features)\n",
    "test_dataset = create_dataset(test_data[0], test_labels[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "# from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "# Initialize the global model\n",
    "global_model = None\n",
    "num_epochs=3\n",
    "# Define the number of clusters (i.e., the number of local models)\n",
    "num_clusters = len(X_partitions)\n",
    "\n",
    "# Train local models\n",
    "local_models = []\n",
    "for i in range(num_clusters):\n",
    "    # Train the local model on the current partition\n",
    "    kmedoids = KMedoids(n_clusters=1, random_state=i)\n",
    "    kmedoids.fit(X_partitions[i])\n",
    "    local_model = kmedoids\n",
    "\n",
    "    # Add the local model to the list of local models\n",
    "    local_models.append(local_model)\n",
    "\n",
    "# Perform federated learning\n",
    "for epoch in range(num_epochs):\n",
    "    # Aggregate the local models\n",
    "    cluster_centers = [model.cluster_centers_ for model in local_models]\n",
    "    global_model = np.mean(cluster_centers, axis=0)\n",
    "\n",
    "    # Train the local models on the global model\n",
    "    for i in range(num_clusters):\n",
    "        # Compute the distance between the global model and the local data\n",
    "        # Reshape input data to a 2D array with one column\n",
    "        X_2d = X_partitions[i].values.reshape(-1, 33)\n",
    "\n",
    "        # Compute distances to cluster centers\n",
    "        distances = pairwise_distances(X_2d, global_model.reshape(1, -1))\n",
    "\n",
    "        # Assign each data point to the nearest cluster\n",
    "        assignments = np.argmin(distances, axis=1)\n",
    "\n",
    "        # Train the local model on the assigned data points\n",
    "        for j in range(local_models[i].n_clusters):\n",
    "            # Select the data points assigned to the current cluster\n",
    "            cluster_data = X_partitions[i][assignments == j]\n",
    "\n",
    "            # Train the local model on the selected data points\n",
    "            local_model = KMedoids(n_clusters=1, random_state=i)\n",
    "            local_model.fit(cluster_data)\n",
    "            local_models[i] = local_model\n",
    "\n",
    "# Use the global model for prediction\n",
    "y_pred = np.argmin(pairwise_distances(X_test, global_model.reshape(1, -1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(Attention, self).__init__()\n",
    "        self.query = nn.Linear(in_features, out_features)\n",
    "        self.key = nn.Linear(in_features, out_features)\n",
    "        self.value = nn.Linear(in_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        q = self.query(x)\n",
    "        k = self.key(x)\n",
    "        v = self.value(x)\n",
    "\n",
    "        attn_scores = torch.matmul(q, k.transpose(-2, -1))\n",
    "        attn_scores = F.softmax(attn_scores, dim=-1)\n",
    "\n",
    "        output = torch.matmul(attn_scores, v)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "# Define the local models\n",
    "num_clusters = 3\n",
    "local_models = []\n",
    "for i in range(num_clusters):\n",
    "    # Train the local model on the current partition using DBSCAN\n",
    "    dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "    dbscan.fit(X_partitions[i])\n",
    "    local_model = dbscan\n",
    "\n",
    "    # Add the local model to the list of local models\n",
    "    local_models.append(local_model)\n",
    "\n",
    "# Define the global model\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dense1 = nn.Linear(num_features, 64)\n",
    "        self.dense2 = nn.Linear(64, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.dense1(x))\n",
    "        x = self.dense2(x)\n",
    "        return x\n",
    "\n",
    "global_model = MyModel(num_features=X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HIMANSHU\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HIMANSHU\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HIMANSHU\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.4969, Accuracy: 0.7728, Precision: 0.4969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HIMANSHU\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.4969, Accuracy: 0.7710, Precision: 0.4969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HIMANSHU\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HIMANSHU\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HIMANSHU\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.4969, Accuracy: 0.7692, Precision: 0.4969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HIMANSHU\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.4969, Accuracy: 0.7675, Precision: 0.4969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HIMANSHU\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HIMANSHU\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HIMANSHU\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.4969, Accuracy: 0.7659, Precision: 0.4969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HIMANSHU\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.4969, Accuracy: 0.7644, Precision: 0.4969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HIMANSHU\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HIMANSHU\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HIMANSHU\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.4969, Accuracy: 0.7629, Precision: 0.4969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HIMANSHU\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.4969, Accuracy: 0.7615, Precision: 0.4969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HIMANSHU\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HIMANSHU\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HIMANSHU\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.4969, Accuracy: 0.7602, Precision: 0.4969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HIMANSHU\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.4969, Accuracy: 0.7589, Precision: 0.4969\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder  # Import the LabelEncoder class\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = optim.SGD(global_model.parameters(), lr=0.1)\n",
    "loss_fn = F.cross_entropy\n",
    "\n",
    "# Train the global model using federated learning\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Update the global model using local models\n",
    "    for i in range(len(X_partitions)):\n",
    "        # Get the data from the current partition\n",
    "        x = torch.from_numpy(X_partitions[i].values).float()\n",
    "\n",
    "        label_encoder = LabelEncoder()\n",
    "        y = label_encoder.fit_transform(y_partitions[i])\n",
    "        y = torch.from_numpy(y).long()\n",
    "\n",
    "        # Compute the local gradients and update the global model\n",
    "        local_model = local_models[i]\n",
    "        preds = local_model.fit_predict(x)\n",
    "        mask = preds != -1\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(global_model(x[mask]), y[mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate the global model\n",
    "    with torch.no_grad():\n",
    "      x = torch.from_numpy(X.to_numpy()).float()\n",
    "      y = torch.from_numpy(y.numpy()).long()\n",
    "      num_samples = min(x.shape[0], y.shape[0], 8000)\n",
    "      indices = torch.randperm(num_samples)\n",
    "      x = x[indices]\n",
    "      y = y[indices]\n",
    "\n",
    "      # Compute the loss and accuracy\n",
    "      accuracy = loss_fn(global_model(x), y)\n",
    "      preds = torch.argmax(global_model(x), dim=1)\n",
    "      loss = torch.mean((preds == y).float())\n",
    "      precision = torch.sum((preds == y).float() * (y == 1).float()) / torch.sum((preds == 1).float())\n",
    "\n",
    "      # Print the epoch, loss, accuracy, and precision\n",
    "      print(f'Epoch {epoch + 1}, Loss: {loss.item():.4f}, Accuracy: {accuracy.item():.4f}, Precision: {precision.item():.4f}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
